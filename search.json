[
  {
    "objectID": "07-centrality.html",
    "href": "07-centrality.html",
    "title": "Measures of Network Centrality",
    "section": "",
    "text": "Centrality measures assess the importance of an actor’s position within a network. We will explore the most important ones: degree centrality, closeness centrality, betweenness centrality, and eigenvector centrality. While other centrality measures exist, they are often related to one of these four.\nWe again start by loading the statnet suite (which contains the network and sna packages):\nlibrary(statnet)",
    "crumbs": [
      "Node-level indicators",
      "Centrality measures"
    ]
  },
  {
    "objectID": "07-centrality.html#marriages-among-florentine-families",
    "href": "07-centrality.html#marriages-among-florentine-families",
    "title": "Measures of Network Centrality",
    "section": "Marriages among Florentine Families",
    "text": "Marriages among Florentine Families\nWe will demonstrate the various centrality mesures using the florentine datasets contained in the network package, which contain the marriage and business ties among Renaissance Florentine families. The dataset was originally prepared by Padgett (1994) in his analysis of the Medici’s rise to power. Since the data is already prepared as a set of network objects, we can skip conversion this time.\nWe make the datasets available with a call to data(...):\n\ndata(florentine)\n\nBefore we start measuring centrality, let’s have a brief look at the marriage network. First, we get the names of the families which are stored as a vertex attribute in the flomarriage network object. We can extract a vertex attribute using the %v% pipe:\n\nfamily_names &lt;- flomarriage %v% \"vertex.names\"\n\nNow lets plot the network, labeling the nodes with the extracted names:\n\ngplot(flomarriage,\n      gmode = \"graph\",\n      label = family_names,\n      vertex.col = \"grey20\",\n      edge.col = \"grey70\",\n      pad=1)",
    "crumbs": [
      "Node-level indicators",
      "Centrality measures"
    ]
  },
  {
    "objectID": "07-centrality.html#degree-centrality",
    "href": "07-centrality.html#degree-centrality",
    "title": "Measures of Network Centrality",
    "section": "Degree Centrality",
    "text": "Degree Centrality\nDegree centrality is just the number of edges connected to a node, which we can compute using the degree(...) function from the sna package. Calling the function on a network returns a vector with the centrality score for each node in the network:\n\ndeg = degree(flomarriage, gmode=\"graph\")\ndeg\n\n [1] 1 3 2 3 3 1 4 1 6 1 3 0 3 2 4 3\n\n\nWe specify the gmode=\"graph\" argument because the marriage network is undirected.\nIf we want to compare centralities visually, we can scale the node size in a network using the vertex.cex (cex = character expansion factor) argument:\n\ngplot(flomarriage,\n      gmode = \"graph\",\n      label = family_names,\n      vertex.cex = sqrt(deg),\n      vertex.col = \"grey20\",\n      edge.col = \"grey70\",\n      pad=1)\n\n\n\n\n\n\n\n\nInstead of using degrees directly, we use the square root of degrees because otherwise some nodes will be too large. Here, we can see that the Medici are the most central family in the network in that they have the most marriage ties to other Florentine families.\nIn case we are more interested in the general distribution of centrality in the network, we can plot a histogram of degrees:\n\nhist(deg, xlab = \"Degree centrality\", main = \"Degree distribution\")\n\n\n\n\n\n\n\n\nThis is often more useful for learning something about the structure of large networks, where the network graph quickly becomes unreadable.\n\nDegree for Directed Networks\nIn directed graphs, we distinguish between indegree and outdegree, i.e. the number of incoming and outgoing edges, respectively.\nTo compute these, we first need to specify gmode=\"digraph\" in the degree() function call. We then have the choice between cmode=\"indegree\", cmode=\"outdegree\", and cmode=\"freeman\", where the freeman option is just the sum of in- and outdegrees.",
    "crumbs": [
      "Node-level indicators",
      "Centrality measures"
    ]
  },
  {
    "objectID": "07-centrality.html#closeness-centrality",
    "href": "07-centrality.html#closeness-centrality",
    "title": "Measures of Network Centrality",
    "section": "Closeness Centrality",
    "text": "Closeness Centrality\nCloseness centrality measures how close an actor is to all other actors in the network, including indirect contacts. It is the inverse of a node’s farness, where farness is the sum of the shortest path distances to all other nodes.\nThere is a function for calculating closeness centrality which similarly to the degree function requires specifying the network mode via gmode. In a directed network, edge directions can additionally be ignored by specifying cmode=\"undirected\".\nHowever, if we call the closeness(...) function on the marriage network, we get an unexpected result:\n\ncloseness(flomarriage, gmode = \"graph\")\n\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n\n\nBecause the network contains an isolate node and paths to isolated nodes are specified to have infinite length, our farness is infinite. Accordingly, closeness is 0 for all nodes because \\(1/\\infty = 0\\).\n\nRemove Isolates\nOne way to tackle the above is to remove isolated nodes from the network, which can be useful more generally. To do so, we first identify all isolated nodes in the network using the isolates(...) function:\n\nisol &lt;- isolates(flomarriage)\nisol\n\n[1] 12\n\n\nThis tells us that the 12th node in the network is isolated. To get all nodes that are not isolated, we create a list of all node indices and remove the isolated ones:\n\nnoisol &lt;- seq(network.size(flomarriage))[-isol]\nnoisol\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16\n\n\nWith this list we can now use the %s% operator to generate a subset of the network containing only the nodes that are not isolated:\n\nflomarriage_noisol &lt;- flomarriage %s% noisol\n\nCalculating closeness now yields meaningful results.\n\ncloseness(flomarriage_noisol, cmode = \"undirected\")\n\n [1] 0.3684211 0.4827586 0.4375000 0.4000000 0.3888889 0.3333333 0.4666667\n [8] 0.3255814 0.5600000 0.2857143 0.3684211 0.5000000 0.3888889 0.4375000\n[15] 0.4827586\n\n\n\n\nSum-of-Inverse Distances Closeness\nAnother approach to handle infinite geodesic distances in closeness calculations is using the sum-of-inverse-distances method. this approach reformulates closeness as the sum of inverse distances instead of the inverse of the sum of distances, which means that just the term involving the isolate node will be zero.\nWe can calculate closeness this way by specifying cmode = \"suminvundir\":\n\nclos &lt;- closeness(flomarriage,\n                  gmode = \"graph\",\n                  cmode = \"suminvundir\") \nclos\n\n [1] 0.3944444 0.5222222 0.4722222 0.4800000 0.4611111 0.3555556 0.5388889\n [8] 0.3577778 0.6333333 0.3177778 0.4522222 0.0000000 0.5333333 0.4388889\n[15] 0.5222222 0.5222222\n\n\nWe can see that this yields similar results compared to when the isolate node is dropped and just sets the closeness of node 12 to zero.",
    "crumbs": [
      "Node-level indicators",
      "Centrality measures"
    ]
  },
  {
    "objectID": "07-centrality.html#betweenness-centrality",
    "href": "07-centrality.html#betweenness-centrality",
    "title": "Measures of Network Centrality",
    "section": "Betweenness Centrality",
    "text": "Betweenness Centrality\nBetweenness centrality measures the extent to which a node lies on the shortest paths between all other nodes, effectively controlling network flow where traffic is assumed to always follows the shortest path.\nAs before, there is a function to compute this, with arguments to control how to treat directed edges:\n\nbet &lt;- betweenness(flomarriage, gmode = \"graph\") \nbet \n\n [1]  0.000000 19.333333  8.500000  9.500000  5.000000  0.000000 23.166667\n [8]  0.000000 47.500000  0.000000  2.000000  0.000000 10.333333 13.000000\n[15]  9.333333  8.333333\n\n\n\nNormalize by Theoretical Maximum\nBecause betweenness scores can get very large quickly, it can make sense to normalize them agains the theoretical maximum value. This maximum is achieved by a star graph (just one noded connected to all others) and can be computed just using the network size \\(N\\):\n\nN &lt;- network.size(flomarriage) \nnorm &lt;- (N-1)*(N-2)/2\nbet_norm &lt;- bet / norm",
    "crumbs": [
      "Node-level indicators",
      "Centrality measures"
    ]
  },
  {
    "objectID": "07-centrality.html#eigenvector-centrality",
    "href": "07-centrality.html#eigenvector-centrality",
    "title": "Measures of Network Centrality",
    "section": "Eigenvector Centrality",
    "text": "Eigenvector Centrality\nEigenvector centrality builds on the recursive intuition that a node is influential if its neighbours are influential. It is defined as the principal eigenvector of the adjacency matrix.\nWe can compute it using the evcent(...) function:\n\neig &lt;- evcent(flomarriage, gmode=\"graph\")\neig\n\n [1] 0.13215429 0.24395611 0.21170525 0.28280009 0.25902617 0.07492271\n [7] 0.28911560 0.08879189 0.43030809 0.04481344 0.27573037 0.00000000\n[13] 0.34155264 0.14591720 0.35598045 0.32584230\n\n\nEigenvector centralities are only useful for comparisons across nodes as the individual scores don’t have a useful interpretation.",
    "crumbs": [
      "Node-level indicators",
      "Centrality measures"
    ]
  },
  {
    "objectID": "07-centrality.html#comparing-centrality-measures",
    "href": "07-centrality.html#comparing-centrality-measures",
    "title": "Measures of Network Centrality",
    "section": "Comparing Centrality Measures",
    "text": "Comparing Centrality Measures\nWhile the above centrality measures build on very different theoretical considerations or intuitions, the are often strongly correlated for many real-world cases.\nWe can inspect this correlation using a pairs plot:\n\nsource(\"helpers/pairsplot.R\") # load helper script to improve the plot\n\nmeasures &lt;- cbind(deg, clos, bet, eig)\n\npairs(measures,\n      upper.panel = panel.cor,\n      diag.panel = panel.hist)\n\n\n\n\n\n\n\n\nIndeed, we see that most of the measures are quite strongly correlated.\nWe can also plot the network multiple times and using the different measures to scale nodes. to make visual comparison easier, we precompute the layout to fix node positions across the plots, using the Fruchterman-Reingold algorithm:\n\nlayout &lt;- network.layout.fruchtermanreingold(flomarriage,\n                                             layout.par = NULL)\n\nTo plot multiple plots into the same figure, we specify par(mfrow = c(2,2)) before calling our plotting functions, which creates a \\(2 \\times 2\\) plot grid:\n\npar(mfrow = c(2,2), mar=c(0,0,3,0))\n\ngplot(flomarriage,\n      coord=layout,\n      gmode=\"graph\",\n      vertex.cex=.3 + .3*deg,\n      main=\"Degree\")\n\ngplot(flomarriage,\n      coord=layout,\n      gmode=\"graph\",\n      vertex.cex=.3 + 2*clos,\n      main=\"Closeness\")\n\ngplot(flomarriage,\n      coord=layout,\n      gmode=\"graph\",\n      vertex.cex=.3 + 5*bet_norm,\n      main=\"Betweenness\")\n\ngplot(flomarriage,\n      coord=layout,\n      gmode=\"graph\",\n      vertex.cex=.3 + 5*eig,\n      main=\"Eigenvector\")\n\n\n\n\n\n\n\n\nAs we can see, the Medici are the most central of the Florentine families according to all four centrality measures.",
    "crumbs": [
      "Node-level indicators",
      "Centrality measures"
    ]
  },
  {
    "objectID": "07-centrality.html#exercises",
    "href": "07-centrality.html#exercises",
    "title": "Measures of Network Centrality",
    "section": "Exercises",
    "text": "Exercises\n\nLoad the lazega advice network into a directed network object.\n\n\n\nSolution\nadjmat &lt;- read.table(\"data/lazega_advice.csv\", \n                     sep =\";\", \n                     header = TRUE, \n                     row.names = 1, \n                     check.names = FALSE)\n\nadjmat &lt;- as.matrix(adjmat)\n\nnet_advice &lt;- network(adjmat)\n\n\n\nPick an appropriate centrality measure to capture the flow of knowledge across the network. Which measure do you choose?\n\n\n\nSolution\n# Betweenness centrality might be a reasonable fit, although it is questionable that knowledge should only flow across shortest paths. A better alternative might be flow betweeness.\n\n\n\nCompute the corresponding node level centralities using an appropriate specification.\n\n\n\nSolution\nbet &lt;- betweenness(net_advice) \n\n\n\nFind the most and least central nodes in the network.\n\n\n\nSolution\nwhich.min(bet)\nwhich.max(bet) \n\n\n\nVisualize the network using the centrality scores.\n\n\n\nSolution\ndev.off()\n\ngplot(net_advice,\n      gmode = \"graph\",\n      vertex.cex = 1 + 0.1*sqrt(bet),\n      vertex.col = \"grey20\",\n      edge.col = \"grey70\")\n\n\n\nVisualize the distribution of the centrality scores using a histogram. What do you learn about the network?\n\n\n\nSolution\nhist(bet,\n     main=\"Distribution of betweenness scores\",\n     xlab=\"Betweenness centrality\")\n\n\n\nCompute the centralization of the network using the chosen centrality measure. What does it tell you?\n\n\n\nSolution\ncentralization(net_advice, betweenness)\n\n\n\nAlso load the friendship network into your R session.\n\n\n\nSolution\nadjmat &lt;- read.table(\"data/lazega_friendship.csv\", \n                     sep =\";\", \n                     header = TRUE, \n                     row.names = 1, \n                     check.names = FALSE)\n\nadjmat &lt;- as.matrix(adjmat)\n\nnet_friendship &lt;- network(adjmat)\n\n\n\nCompute centralities for the friendship network using the same measure as before.\n\n\n\nSolution\nbet_friendship &lt;- betweenness(net_friendship)\n\n\n\nPlot the two networks side-by-side, using the respective centrality scores to scale node size. What do you observe?\n\n\n\nSolution\npar(mfrow = c(1,2), mar=c(0,0,3,0))\n\nlayout &lt;- network.layout.fruchtermanreingold(net_advice,\n                                             layout.par = NULL)\n\ngplot(net_advice,\n      coord=layout,\n      gmode=\"graph\",\n      vertex.col = \"grey20\",\n      vertex.cex = 1 + 0.1*sqrt(bet),\n      edge.col = \"grey70\",\n      main=\"Advice ties\")\n\ngplot(net_friendship,\n      coord=layout,\n      gmode=\"graph\",\n      vertex.col = \"grey20\",\n      vertex.cex = 1 + 0.1*sqrt(bet_friendship),\n      edge.col = \"grey70\",\n      main=\"Friendship ties\")\n\n\n\nPlot a scatter plot of the advice and friendship betweenness scores.\n\n\n\nSolution\ndev.off()\n\nplot(bet, bet_friendship, xlab=\"Advice\", ylab=\"Friendship\")\n\n\n\nCompute the centralization for the friendship network and compare the resulting score to the advice network.\n\n\n\nSolution\ncentralization(net_advice, betweenness)\ncentralization(net_friendship, betweenness)",
    "crumbs": [
      "Node-level indicators",
      "Centrality measures"
    ]
  },
  {
    "objectID": "05-network-construction.html",
    "href": "05-network-construction.html",
    "title": "Representing networks in R",
    "section": "",
    "text": "Networks can be represented in various formats, each offering its own advantages: Edgelists, for example, are good for storing and passing around networks, while adjacency lists or adjacency matrices are often preferable for computation.\nSoftware packages for network analysis, such as statnet or igraph, usually hide the underlying data structure used for computation as an implementation detail while allowing import and export from/to a wide range of formats.\nIn the following, we will make use of the network and sna R packages to explore conversion from and to a range of network representations:\n# uncomment the line below if you have not yet installed the packages\n# install.packages(c(\"network\", \"sna\"))\n\nlibrary(network)\nlibrary(sna)",
    "crumbs": [
      "Networks in `R`",
      "Network represenations"
    ]
  },
  {
    "objectID": "05-network-construction.html#the-edgelist",
    "href": "05-network-construction.html#the-edgelist",
    "title": "Representing networks in R",
    "section": "The edgelist",
    "text": "The edgelist\nThe simplest way to represent a network is as a list of edges, aptly called an edgelist. We can store such an edgelist as a table with two columns where each row represents an edge and the first column holds the sender and the second column the receiver of an edge.\nIn R, one way to represent this would be a data.frame:\n\nedgelist &lt;- data.frame(sender = c(1,1,1), receiver = c(2,3,4))\nedgelist\n\n  sender receiver\n1      1        2\n2      1        3\n3      1        4\n\n\nUsually, we don’t use this edgelist for computing a measure of interest directly. Instead, we convert it to the network type defined in the network package (which is contained in the statnet suite):\n\nnet1 &lt;- network(edgelist, directed = FALSE)\n\nThe network(...) function is quite smart and will often detect the appropriate format from the input argument. Data frames, e.g. will be treated as edgelists, while matrices will be treated as adjacency matrices. The function furthermore supports a wide range of arguments for specifying the kind of network that should be produced (e.g. directed vs. undirected).\nIf we print the produced network net1, it will show us some general information, such as the number of nodes and the number of edges, its basic properties and contained node and edge attributes:\n\nnet1\n\n Network attributes:\n  vertices = 4 \n  directed = FALSE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = FALSE \n  total edges= 3 \n    missing edges= 0 \n    non-missing edges= 3 \n\n Vertex attribute names: \n    vertex.names \n\nNo edge attributes\n\n\nWe can pass this network object to the plethora of functions defined in the network and sna packages, such as gplot(...) to produce a plot of the network graph:\n\ngplot(net1, gmode = \"graph\", label = 1:4)",
    "crumbs": [
      "Networks in `R`",
      "Network represenations"
    ]
  },
  {
    "objectID": "05-network-construction.html#the-adjacency-matrix",
    "href": "05-network-construction.html#the-adjacency-matrix",
    "title": "Representing networks in R",
    "section": "The adjacency matrix",
    "text": "The adjacency matrix\nA second important representation of a network is the adjacency matrix. For a network of size \\(N\\) (i.e., a network with \\(N\\) nodes), the adjacency matrix is a \\(N \\times N\\) matrix (i.e., a matrix with \\(N\\) rows and columns). In this matrix, the cell indicated by the \\(i\\)th row and the \\(j\\)th column is \\(1\\) if there is an edge from node \\(i\\) to node \\(j\\) and \\(0\\) otherwise (for the case of an unweighted network).\nIn R we could construct an adjacency matrix manually using the matrix(...) function:\n\nadjmat &lt;- matrix(data = c(0,1,1,1, \n                          1,0,0,0, \n                          1,0,0,0, \n                          1,0,0,0), nrow = 4, ncol = 4, byrow = T)\n\nadjmat\n\n     [,1] [,2] [,3] [,4]\n[1,]    0    1    1    1\n[2,]    1    0    0    0\n[3,]    1    0    0    0\n[4,]    1    0    0    0\n\n\nAs before for the edgelist, we can pass this matrix to the network(...) function to construct a network object from the adjacency matrix:\n\nnet2 &lt;- network(adjmat, directed = FALSE)\n\nWe can again print and plot this network object to see that it has the same structure as net1, which was constructed from an edgelist representing the same network:\n\nnet2\n\n Network attributes:\n  vertices = 4 \n  directed = FALSE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = FALSE \n  total edges= 3 \n    missing edges= 0 \n    non-missing edges= 3 \n\n Vertex attribute names: \n    vertex.names \n\nNo edge attributes\n\n\n\n gplot(net1, gmode = \"graph\", label = 1:4)\n\n\n\n\n\n\n\n\n\nIndexing into an adjacency matrix\nA couple of sessions ago, we saw how to index into a vector using square brackets (e.g. myvec[1]). We can do the same for our adjacency matrix, using two indices (the first for the row and the second for the column):\n\nadjmat[1,2]\n\n[1] 1\n\n\nThis tells us that there is an edge in our network from node 1 to node 2.\nIndexing into the network is even directly supported for network objects, using the same indexing syntax:\n\nnet1[1,2]\n\n[1] 1\n\n\n\n\nReading an adjacency matrix from a csv file\nWe can also read an adjacency matrix that is stored in a .csv file using, e.g., the built-in read.table(...) function. Here, we need to pass some additional arguments because the file contains row names in the first column (thus we specify row.names = 1) and uses numeric names, which by default are invalid (so we pass check.names = FALSE).\n\nadjmat &lt;- read.table(\"data/lazega_advice.csv\", \n                     sep =\";\", \n                     header = TRUE, \n                     row.names = 1, \n                     check.names = FALSE)\n\nBecause adjmat is a data frame right now but we usually want to represent an adjacency matrix with R’s built-in matrix type, we need to convert it first:\n\nadjmat &lt;- as.matrix(adjmat)\n\nWe can check that the matrix is quadratic (i.e. has as many rows as it has columns):\n\nnrow(adjmat) == ncol(adjmat) \n\n[1] TRUE\n\n\nand that the column names are equal to the row names:\n\nall(colnames(adjmat) == rownames(adjmat))\n\n[1] TRUE\n\n\nNow that we have done some validation that we loaded the data correctly, we can pass the adjacency matrix to the network(...) function to construct a network:\n\nnet &lt;- network(adjmat, directed = TRUE)",
    "crumbs": [
      "Networks in `R`",
      "Network represenations"
    ]
  },
  {
    "objectID": "05-network-construction.html#there-and-back-again",
    "href": "05-network-construction.html#there-and-back-again",
    "title": "Representing networks in R",
    "section": "There and back again",
    "text": "There and back again\nR and the network package allow us to also go the other way, e.g. creating an edgelist from a network object. We can do this by converting the network to a data frame using as.data.frame(...):\n\nel &lt;- as.data.frame(net1)\nel\n\n  .tail .head\n1     1     2\n2     1     3\n3     1     4\n\n\nHere, the .tail column holds the sender for each edge and .head the receiver.\nWe can similarly also convert to an adjacency matrix:\n\nadj &lt;- as.matrix(net1)\nadj\n\n  1 2 3 4\n1 0 1 1 1\n2 1 0 0 0\n3 1 0 0 0\n4 1 0 0 0",
    "crumbs": [
      "Networks in `R`",
      "Network represenations"
    ]
  },
  {
    "objectID": "05-network-construction.html#exercises",
    "href": "05-network-construction.html#exercises",
    "title": "Representing networks in R",
    "section": "Exercises",
    "text": "Exercises\n\nLoad the adjacency matrix contained in the file data/lazega_advice.csv into R.\n\n# Write your code here...\n\nCreate an undirected network from the adjacency matrix.\n\n# Write your code here...\n\nHow many nodes and edges does the network have?\n\n# Write your code here...\n\nPlot the network. Color the nodes black and the edges grey.\n\n# Write your code here...\n\nGet the edgelist for the network and write it to a .csv file.\n\n# Write your code here...\n\nIndex into the adjacency matrix to find out whether node 2 and node 4 are connected.\n\n# Write your code here...",
    "crumbs": [
      "Networks in `R`",
      "Network represenations"
    ]
  },
  {
    "objectID": "03-data-handling.html",
    "href": "03-data-handling.html",
    "title": "R basics III",
    "section": "",
    "text": "Data wrangling refers to all the steps that need to be taken before the actual analysis can be conducted. As such, it is often considered a nuisance that however usually takes a considerable share of the overall effort and code in a research project.\nData wrangling comprises, e.g., filtering out bad data, selecting a subset of available data, reshaping data into a more useful format, or computing derivative measures and summaries. In the following, we will look at some of the most frequently needed operations and how to apply them using the tidyverse.\nThis tutorial only gives a glimpse at the possibilities of data wrangling in R. For a much more comprehensive introduction see the great and free R for Data Science online book.\nIn the following, we will again make use of the gapminder dataset as well as the tidyverse:\n\nlibrary(gapminder)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ngapminder\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\n\n\nOftentimes, we’re only interested in a subset of the observations contained in our data. Say, for example, we only want data on Germany since the 1990s. We can use the filter function to achieve this:\n\nfilter(gapminder, country == \"Germany\", year &gt;= 1990)\n\n# A tibble: 4 × 6\n  country continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Germany Europe     1992    76.1 80597764    26505.\n2 Germany Europe     1997    77.3 82011073    27789.\n3 Germany Europe     2002    78.7 82350671    30036.\n4 Germany Europe     2007    79.4 82400996    32170.\n\n\n\n\n\nSimilarly, we’re often only interested in a subset of the variables. We can use the select command to select only some variables and also to rename them:\n\nselect(gapminder, country, year, life_expectancy=lifeExp)\n\n# A tibble: 1,704 × 3\n   country      year life_expectancy\n   &lt;fct&gt;       &lt;int&gt;           &lt;dbl&gt;\n 1 Afghanistan  1952            28.8\n 2 Afghanistan  1957            30.3\n 3 Afghanistan  1962            32.0\n 4 Afghanistan  1967            34.0\n 5 Afghanistan  1972            36.1\n 6 Afghanistan  1977            38.4\n 7 Afghanistan  1982            39.9\n 8 Afghanistan  1987            40.8\n 9 Afghanistan  1992            41.7\n10 Afghanistan  1997            41.8\n# ℹ 1,694 more rows\n\n\n\n\n\nOften, we want to group our data according to one variable (e.g., the continent) and then compute a summary for each of the groups based on another variable (e.g., the mean life expectancy). We can do this by first creating a grouped version of our data using group_by and then using summarize to compute a summary for each group:\n\ndata_grouped &lt;- group_by(gapminder, continent)\nsummarize(data_grouped, lifeExp_mean = mean(lifeExp))\n\n# A tibble: 5 × 2\n  continent lifeExp_mean\n  &lt;fct&gt;            &lt;dbl&gt;\n1 Africa            48.9\n2 Americas          64.7\n3 Asia              60.1\n4 Europe            71.9\n5 Oceania           74.3\n\n\nNote that this drops all other variables except for the grouping variable and the summary variable.\n\n\n\nTypically, data wrangling implies combining multiple of these steps. R allows us to build data pipelines with the pipe operator |&gt; which pipes the output of the operation to the left into the first argument of the operation to the right. Instead of writing filter(data, year &gt; 1990) we could for example write data |&gt; filter(year &gt; 1990).\n\nfilter(gapminder, year &gt; 1990)\n\n# A tibble: 568 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1992    41.7 16317921      649.\n 2 Afghanistan Asia       1997    41.8 22227415      635.\n 3 Afghanistan Asia       2002    42.1 25268405      727.\n 4 Afghanistan Asia       2007    43.8 31889923      975.\n 5 Albania     Europe     1992    71.6  3326498     2497.\n 6 Albania     Europe     1997    73.0  3428038     3193.\n 7 Albania     Europe     2002    75.7  3508512     4604.\n 8 Albania     Europe     2007    76.4  3600523     5937.\n 9 Algeria     Africa     1992    67.7 26298373     5023.\n10 Algeria     Africa     1997    69.2 29072015     4797.\n# ℹ 558 more rows\n\n\nOn its own, this is not very useful. However, this syntax allows us to chain multiple operations from left to right or from top to bottom, which is easier to read than nested functions. consider for example the following:\n\nselect(filter(gapminder, year &gt; 1990, country == \"Germany\"), year, lifeExp)\n\n# A tibble: 4 × 2\n   year lifeExp\n  &lt;int&gt;   &lt;dbl&gt;\n1  1992    76.1\n2  1997    77.3\n3  2002    78.7\n4  2007    79.4\n\n# is equivalent to\n\ngapminder |&gt;\n  filter(year &gt; 1990, country == \"Germany\") |&gt;\n  select(year, lifeExp)\n\n# A tibble: 4 × 2\n   year lifeExp\n  &lt;int&gt;   &lt;dbl&gt;\n1  1992    76.1\n2  1997    77.3\n3  2002    78.7\n4  2007    79.4\n\n\n\n\n\n\nBuild a data pipeline that computes the mean life expectancy and the mean per-capita GDP in Europe for each 5-year period since the 1980s.\n\n\n\nSolution\ngapminder |&gt;\n  filter(year &gt;= 1980) |&gt;\n  group_by(country, year) |&gt;\n  summary(\n    lifeExp_mean=mean(lifeExp),\n    gdpPercap_mean=mean(gdpPercap))\n\n\n\nReshape the gapminder data into a country-by-year matrix, i.e., a data frame where each row is a country, each column is a year and each cell contains the GDP for that country-year pair.\n\n\n\nSolution\ngapminder |&gt;\n  select(country, year, gdpPercap) |&gt;\n  pivot_wider(names_from=year, values_from=gdpPercap)\n\n\n\nHow many entries in gapminder are from after 1960 and come from OECD countries?\nHere’s a list of all countries in the OECD: “Australia”, “Austria”, “Belgium”, “Canada”, “Chile”, “Colombia”, “Costa Rica”, “Czech Republic”, “Denmark”, “Estonia”, “Finland”, “France”, “Germany”, “Greece”, “Hungary”, “Iceland”, “Ireland”, “Israel”, “Italy”, “Japan”, “Korea”, “Latvia”, “Lithuania”, “Luxembourg”, “Mexico”, “Netherlands”, “New Zealand”, “Norway”, “Poland”, “Portugal”, “Slovak Republic”, “Slovenia”, “Spain”, “Sweden”, “Switzerland”, “Turkey”, “United Kingdom”, “United States”\n\n\n\nSolution\noecd &lt;- c(\"Australia\", \"Austria\", \"Belgium\", \"Canada\", \"Chile\", \"Colombia\", \"Costa Rica\", \"Czech Republic\", \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Iceland\", \"Ireland\", \"Israel\", \"Italy\", \"Japan\", \"Korea\", \"Latvia\", \"Lithuania\", \"Luxembourg\", \"Mexico\", \"Netherlands\", \"New Zealand\", \"Norway\", \"Poland\", \"Portugal\", \"Slovak Republic\", \"Slovenia\", \"Spain\", \"Sweden\", \"Switzerland\", \"Turkey\", \"United Kingdom\", \"United States\")\n\ngapminder |&gt; filter(year &gt; 1960, country %in% oecd) |&gt; nrow()",
    "crumbs": [
      "`R` programming basics",
      "Data wrangling"
    ]
  },
  {
    "objectID": "03-data-handling.html#filtering-rows",
    "href": "03-data-handling.html#filtering-rows",
    "title": "R basics III",
    "section": "",
    "text": "Oftentimes, we’re only interested in a subset of the observations contained in our data. Say, for example, we only want data on Germany since the 1990s. We can use the filter function to achieve this:\n\nfilter(gapminder, country == \"Germany\", year &gt;= 1990)\n\n# A tibble: 4 × 6\n  country continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Germany Europe     1992    76.1 80597764    26505.\n2 Germany Europe     1997    77.3 82011073    27789.\n3 Germany Europe     2002    78.7 82350671    30036.\n4 Germany Europe     2007    79.4 82400996    32170.",
    "crumbs": [
      "`R` programming basics",
      "Data wrangling"
    ]
  },
  {
    "objectID": "03-data-handling.html#selecting-and-renaming-variables",
    "href": "03-data-handling.html#selecting-and-renaming-variables",
    "title": "R basics III",
    "section": "",
    "text": "Similarly, we’re often only interested in a subset of the variables. We can use the select command to select only some variables and also to rename them:\n\nselect(gapminder, country, year, life_expectancy=lifeExp)\n\n# A tibble: 1,704 × 3\n   country      year life_expectancy\n   &lt;fct&gt;       &lt;int&gt;           &lt;dbl&gt;\n 1 Afghanistan  1952            28.8\n 2 Afghanistan  1957            30.3\n 3 Afghanistan  1962            32.0\n 4 Afghanistan  1967            34.0\n 5 Afghanistan  1972            36.1\n 6 Afghanistan  1977            38.4\n 7 Afghanistan  1982            39.9\n 8 Afghanistan  1987            40.8\n 9 Afghanistan  1992            41.7\n10 Afghanistan  1997            41.8\n# ℹ 1,694 more rows",
    "crumbs": [
      "`R` programming basics",
      "Data wrangling"
    ]
  },
  {
    "objectID": "03-data-handling.html#group-summaries",
    "href": "03-data-handling.html#group-summaries",
    "title": "R basics III",
    "section": "",
    "text": "Often, we want to group our data according to one variable (e.g., the continent) and then compute a summary for each of the groups based on another variable (e.g., the mean life expectancy). We can do this by first creating a grouped version of our data using group_by and then using summarize to compute a summary for each group:\n\ndata_grouped &lt;- group_by(gapminder, continent)\nsummarize(data_grouped, lifeExp_mean = mean(lifeExp))\n\n# A tibble: 5 × 2\n  continent lifeExp_mean\n  &lt;fct&gt;            &lt;dbl&gt;\n1 Africa            48.9\n2 Americas          64.7\n3 Asia              60.1\n4 Europe            71.9\n5 Oceania           74.3\n\n\nNote that this drops all other variables except for the grouping variable and the summary variable.",
    "crumbs": [
      "`R` programming basics",
      "Data wrangling"
    ]
  },
  {
    "objectID": "03-data-handling.html#data-pipelines",
    "href": "03-data-handling.html#data-pipelines",
    "title": "R basics III",
    "section": "",
    "text": "Typically, data wrangling implies combining multiple of these steps. R allows us to build data pipelines with the pipe operator |&gt; which pipes the output of the operation to the left into the first argument of the operation to the right. Instead of writing filter(data, year &gt; 1990) we could for example write data |&gt; filter(year &gt; 1990).\n\nfilter(gapminder, year &gt; 1990)\n\n# A tibble: 568 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1992    41.7 16317921      649.\n 2 Afghanistan Asia       1997    41.8 22227415      635.\n 3 Afghanistan Asia       2002    42.1 25268405      727.\n 4 Afghanistan Asia       2007    43.8 31889923      975.\n 5 Albania     Europe     1992    71.6  3326498     2497.\n 6 Albania     Europe     1997    73.0  3428038     3193.\n 7 Albania     Europe     2002    75.7  3508512     4604.\n 8 Albania     Europe     2007    76.4  3600523     5937.\n 9 Algeria     Africa     1992    67.7 26298373     5023.\n10 Algeria     Africa     1997    69.2 29072015     4797.\n# ℹ 558 more rows\n\n\nOn its own, this is not very useful. However, this syntax allows us to chain multiple operations from left to right or from top to bottom, which is easier to read than nested functions. consider for example the following:\n\nselect(filter(gapminder, year &gt; 1990, country == \"Germany\"), year, lifeExp)\n\n# A tibble: 4 × 2\n   year lifeExp\n  &lt;int&gt;   &lt;dbl&gt;\n1  1992    76.1\n2  1997    77.3\n3  2002    78.7\n4  2007    79.4\n\n# is equivalent to\n\ngapminder |&gt;\n  filter(year &gt; 1990, country == \"Germany\") |&gt;\n  select(year, lifeExp)\n\n# A tibble: 4 × 2\n   year lifeExp\n  &lt;int&gt;   &lt;dbl&gt;\n1  1992    76.1\n2  1997    77.3\n3  2002    78.7\n4  2007    79.4",
    "crumbs": [
      "`R` programming basics",
      "Data wrangling"
    ]
  },
  {
    "objectID": "03-data-handling.html#exercises",
    "href": "03-data-handling.html#exercises",
    "title": "R basics III",
    "section": "",
    "text": "Build a data pipeline that computes the mean life expectancy and the mean per-capita GDP in Europe for each 5-year period since the 1980s.\n\n\n\nSolution\ngapminder |&gt;\n  filter(year &gt;= 1980) |&gt;\n  group_by(country, year) |&gt;\n  summary(\n    lifeExp_mean=mean(lifeExp),\n    gdpPercap_mean=mean(gdpPercap))\n\n\n\nReshape the gapminder data into a country-by-year matrix, i.e., a data frame where each row is a country, each column is a year and each cell contains the GDP for that country-year pair.\n\n\n\nSolution\ngapminder |&gt;\n  select(country, year, gdpPercap) |&gt;\n  pivot_wider(names_from=year, values_from=gdpPercap)\n\n\n\nHow many entries in gapminder are from after 1960 and come from OECD countries?\nHere’s a list of all countries in the OECD: “Australia”, “Austria”, “Belgium”, “Canada”, “Chile”, “Colombia”, “Costa Rica”, “Czech Republic”, “Denmark”, “Estonia”, “Finland”, “France”, “Germany”, “Greece”, “Hungary”, “Iceland”, “Ireland”, “Israel”, “Italy”, “Japan”, “Korea”, “Latvia”, “Lithuania”, “Luxembourg”, “Mexico”, “Netherlands”, “New Zealand”, “Norway”, “Poland”, “Portugal”, “Slovak Republic”, “Slovenia”, “Spain”, “Sweden”, “Switzerland”, “Turkey”, “United Kingdom”, “United States”\n\n\n\nSolution\noecd &lt;- c(\"Australia\", \"Austria\", \"Belgium\", \"Canada\", \"Chile\", \"Colombia\", \"Costa Rica\", \"Czech Republic\", \"Denmark\", \"Estonia\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Iceland\", \"Ireland\", \"Israel\", \"Italy\", \"Japan\", \"Korea\", \"Latvia\", \"Lithuania\", \"Luxembourg\", \"Mexico\", \"Netherlands\", \"New Zealand\", \"Norway\", \"Poland\", \"Portugal\", \"Slovak Republic\", \"Slovenia\", \"Spain\", \"Sweden\", \"Switzerland\", \"Turkey\", \"United Kingdom\", \"United States\")\n\ngapminder |&gt; filter(year &gt; 1960, country %in% oecd) |&gt; nrow()",
    "crumbs": [
      "`R` programming basics",
      "Data wrangling"
    ]
  },
  {
    "objectID": "01-basics.html",
    "href": "01-basics.html",
    "title": "R Basics I",
    "section": "",
    "text": "Quarto notebooks\n\n\n\nAny applied project is an iterative process which involves a back-and-forth between writing code, looking at data and plots, and taking notes. This document is a Quarto notebook, which allows you to combine prose with code and code output, such as tables or plots, in one place.\nWe can compile this notebook to various output formats with the big blue Render button to produce nice-looking and reproducible reports.\nQuarto allows us to combine different programming languages in one environment. We can include a code chunk containing executable code by writing / in an empty line of the notebook.",
    "crumbs": [
      "`R` programming basics",
      "Variables and functions"
    ]
  },
  {
    "objectID": "01-basics.html#variables",
    "href": "01-basics.html#variables",
    "title": "R Basics I",
    "section": "Variables",
    "text": "Variables\nTo assign a value to a name, in R you use the assignment operator &lt;-:\n\nx &lt;- 10 # this is a comment\n\nWe can now reference the value using the variable:\n\nx * 2\n\n[1] 20\n\n\nYou can assign arbitrary values to variables, not just numbers:\n\nname &lt;- \"Jakob\"\n\nHere, I assigned the string \"Jakob\" to the variable name. Strings are how R represents text and are constructed with quotation marks (\"...\").\nVariable names are case sensitive but cannot include spaces or special symbols, except for underscores (_) and period marks (.):\n\nthis is an invalid name &lt;- 1\nthis-too &lt;- 3\n\nError: &lt;text&gt;:1:6: unexpected symbol\n1: this is\n         ^\n\n\n\nbut_THIS_isnt &lt;- 5",
    "crumbs": [
      "`R` programming basics",
      "Variables and functions"
    ]
  },
  {
    "objectID": "01-basics.html#functions",
    "href": "01-basics.html#functions",
    "title": "R Basics I",
    "section": "Functions",
    "text": "Functions\nTo perform any kind of operation, you use a function. E.g., to round a decimal number, we use the round function:\n\nround(3.14159)\n\n[1] 3\n\n\nFunctions can take inputs, called the arguments, which go into the parentheses right after the function name. Functions might also return some output, but they don’t have to. Most things you do in R will involve calling a function on some arguments and assigning the result to a variable name:\n\nIn R, arguments can be specified by name or by position, and often have default values:\n\nround(3.14159, digits=2)\n\n[1] 3.14\n\n\nYou can define your own functions, which can themselves call other functions:\n\ngreet &lt;- function(name) {\n  paste(\"Hello\", name)\n}\n\nHere, we defined a function called greet, which has an argument called name that takes in a string and returns a string with a greeting to the passed name. Let’s call it:\n\ngreet(name=\"Daniel\")\n\n[1] \"Hello Daniel\"\n\n\nNote that the name argument only exists as a referenceable variable within the scope of the function.\nWe can of course also call the function on a variable ‘storing’ a name:\n\ny &lt;- \"Daniel\"\ngreet(y)\n\n[1] \"Hello Daniel\"",
    "crumbs": [
      "`R` programming basics",
      "Variables and functions"
    ]
  },
  {
    "objectID": "01-basics.html#exercises-i-10-15-min",
    "href": "01-basics.html#exercises-i-10-15-min",
    "title": "R Basics I",
    "section": "Exercises I (10-15 min)",
    "text": "Exercises I (10-15 min)\n\n\n\n\n\n\nGetting Help: ChatGPT & Co.\n\n\n\nProgramming frequently involves solving new problems for which you don’t know the solution yet. Luckily, most problems have been solved before by other people. Accordingly, many solutions to frequent problems can be found in a variety of places online.\nLarge Language Models (LLMs), such as ChatGPT, can be helpful in synthesizing these solutions. But be aware, “AI” tools are not all-knowing and will make mistakes or propose non-optimal solutions, just as the people they learned it from did.\nWith this in mind, the exercises we do here will frequently go beyond the contents we discussed before. This reflects the process of any real-world project and so will prepare you for pursuing your own research with R.\n\n\n\nAssign your name to a variable and call the greet(...) function on it which we defined before.\n\n\n\nSolution\nme &lt;- \"Jakob\"\ngreet(me)\n\n\n\nCopy the greet() function from before, rename it to greet_spanish and change it so that it says Hola instead of Hello .\n\n\n\nSolution\ngreet_spanish &lt;- function(name) {\n  paste(\"Hola\", name)\n}\n\ngreet_spanish(me)\n\n\n\nCopy the greet() function again but this time change it so that it takes the greeting as a second function argument instead of specifying it in the function body.\n\n\n\nSolution\ngreet_generic &lt;- function(greeting, name) {\n  paste(greeting, name)\n}\n\ngreet_generic(\"Gruezi\", me)\n\n\n\nCreate a vector with the numbers from 1 to 100 and assign it to a variable called x.\n\n\n\nSolution\nx &lt;- 1:100\n\n\n\nFind a function that sorts its input in reverse order and apply it to x.\n\n\n\nSolution\nsort(x, decreasing=TRUE)",
    "crumbs": [
      "`R` programming basics",
      "Variables and functions"
    ]
  },
  {
    "objectID": "01-basics.html#vectors",
    "href": "01-basics.html#vectors",
    "title": "R Basics I",
    "section": "Vectors",
    "text": "Vectors\nThe most basic data structure in R is the vector. It contains elements of the same basic data type (e.g. numeric or character). We can create one with the c() function (for combine or concatenate):\n\nmy_vector &lt;- c(1,3,4,2)\nmy_vector\n\n[1] 1 3 4 2\n\n\nIn fact, even single numbers are just one-element vectors in R. Most operations in R ‘vectorize’, i.e. are applied element-wise:\n\nsqrt(my_vector)\n\n[1] 1.000000 1.732051 2.000000 1.414214\n\n\nor\n\nmy_vector == 2\n\n[1] FALSE FALSE FALSE  TRUE\n\n\n\nIndexing\nTo obtain a specific element from a vector we use square braces for an operation called indexing:\n\nmy_vector[2]\n\n[1] 3\n\n\nYou can also use another vector as an indexing variable:\n\nmy_idx &lt;- c(1,2,3)\nmy_vector[my_idx]\n\n[1] 1 3 4\n\nmy_vector[1:3]\n\n[1] 1 3 4",
    "crumbs": [
      "`R` programming basics",
      "Variables and functions"
    ]
  },
  {
    "objectID": "01-basics.html#lists",
    "href": "01-basics.html#lists",
    "title": "R Basics I",
    "section": "Lists",
    "text": "Lists\nVectors have the constraint that all their elements need to have the same basic data type:\n\nc(\"f\", 1) # 1 is converted to string \n\n[1] \"f\" \"1\"\n\n\nA more flexible kind of container is the list, which allows you to store arbitrary data types, e.g.:\n\nmylist &lt;- list(\n    mynumber=1, \n    mystring=\"abc\", \n    mylist=list(x=1, b=\"a\")\n)\n\nYou can access the elements of a list with double square brackets:\n\nmylist[[2]]\n\n[1] \"abc\"\n\n\nYou can also access elements by name using the $ symbol, which is often preferable:\n\nmylist$mystring\n\n[1] \"abc\"\n\n\nNew elements can also be added to a list this way:\n\nmylist$newstring &lt;- \"xyz\"\nmylist\n\n$mynumber\n[1] 1\n\n$mystring\n[1] \"abc\"\n\n$mylist\n$mylist$x\n[1] 1\n\n$mylist$b\n[1] \"a\"\n\n\n$newstring\n[1] \"xyz\"",
    "crumbs": [
      "`R` programming basics",
      "Variables and functions"
    ]
  },
  {
    "objectID": "01-basics.html#data-frames",
    "href": "01-basics.html#data-frames",
    "title": "R Basics I",
    "section": "Data frames",
    "text": "Data frames\nA special kind of list that is used to represent tabular data (as in an excel spreadsheet) is the data.frame. The basic entries of a data frame are the columns in the table. Columns are vectors, and thus have to hold elements of the same basic data type (e.g. numbers). In the context of a data frame, the column vectors are also constrained to be the same length:\n\ndf &lt;- data.frame(\n  name = c(\"Tim\", \"Tom\", \"Tina\"),\n  age = c(21, 23, 24),\n  subject = c(\"Geography\", \"Economics\", \"Physics\")\n)\n\ndf\n\n  name age   subject\n1  Tim  21 Geography\n2  Tom  23 Economics\n3 Tina  24   Physics\n\n\nTo access the columns of a data frame, we can again use the $ symbol, as with regular lists:\n\ndf$subject\n\n[1] \"Geography\" \"Economics\" \"Physics\"  \n\n\nData frames are the bread-and-butter data structure of most regular data analysis projects, so you should get comfortable with them.",
    "crumbs": [
      "`R` programming basics",
      "Variables and functions"
    ]
  },
  {
    "objectID": "01-basics.html#exercises-ii-10-15-min",
    "href": "01-basics.html#exercises-ii-10-15-min",
    "title": "R Basics I",
    "section": "Exercises II (10-15 min)",
    "text": "Exercises II (10-15 min)\n\n\n\n\n\n\nPackages\n\n\n\nWhile R comes ‘batteries included’ in many regards, much of the functionality that makes R useful is located in packages. We load a package with the library function.\nIf we try to load a package which has not yet been installed, RStudio will prompt us to install it. Alternatively, we can install a package via install.packages(\"stringr\") (note the quotes).\nIf you put install.packages(\"...\") into a code cell, you should probably delete it after running to avoid reinstalling packages everytime you run the notebook. Instead you can also install your packages via the console.\n\n\n\nWhat is wrong with this piece of code? Find the errors and fix them.\n\n\nmydf &lt;- data.frame(\n  country &lt;- (\"Germany\", \"France\", \"Austria\"),\n  capital &lt;- c(\"Berlin\", \"Paris\"),\n  gdp &lt;- c(4.12, 2.80 0.48)\n\n\nSample 10 numbers from a normal distribution with mean 0 and standard deviation 2 and assign them to a variable called s.\n\n\n\nSolution\ns &lt;- rnorm(10, mean=0, sd=2)\n\n\n\nCompute the empirical mean and the standard deviation of the numbers in s.\n\n\n\nSolution\nmean(s)\nsd(s)\n\n\n\nFind the minimum and the maximum value of s programmatically.\n\n\n\nSolution\nmin(s)\nmax(s)\n\n\n\nWhat are the indexes of the minimum and maximum value?\n\n\n\nSolution\nwhich.min(s)\nwhich.max(s)\n\n\n\nFind (the indexes of) all values in s that are larger than 0:\n\n\n\nSolution\nidx &lt;- which(s &gt; 0)\ns[idx]\n\n\n\nSplit the following string at the comma to produce a vector of three strings:\n\n\nnames &lt;- \"Tim,Tom,Tina\"\n\n\n\nSolution\nlibrary(stringr)\nstr_split1(names, \",\")\n\n\n\nHere is a slightly more complex piece of code. Use your online resources to get help with understanding what each line is doing.\n\n\nlibrary(ggplot2)\n\ndata &lt;- data.frame(\n  group = rep(c(\"A\", \"B\", \"C\"), each = 50),\n  value = c(rnorm(50, mean = 10, sd = 2), \n            rnorm(50, mean = 12, sd = 2),\n            rnorm(50, mean = 15, sd = 2))\n)\n\nggplot(data, aes(x = group, y = value)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot Example\", x = \"Group\", y = \"Value\")",
    "crumbs": [
      "`R` programming basics",
      "Variables and functions"
    ]
  },
  {
    "objectID": "00-index.html",
    "href": "00-index.html",
    "title": "A first course in social network analysis with R",
    "section": "",
    "text": "This website accompanies the practical introduction to social network analysis with R taught at the LMU Department of Geography. The course is part of the Bachelor Degree module Special Anthropogeography and is usually taught in the summer term.\nThe course is targeted at students with limited programming experience. Accordingly, the first couple of sessions include a general introduction to some R programming concepts, without delving deeply into the fundamentals.",
    "crumbs": [
      "Getting started",
      "About this course"
    ]
  },
  {
    "objectID": "00-index.html#course-structure",
    "href": "00-index.html#course-structure",
    "title": "A first course in social network analysis with R",
    "section": "Course structure",
    "text": "Course structure\n\n\n\nSession\nTopic\n\n\n\n\n1 - 3\nIntroduction to R\n\n\n4 - 5\nBasic network properties\n\n\n6 - 8\nCentrality measures & ego networks\n\n\n9 - 11\nNetwork communities & exogeneous groups\n\n\n12\nModeling network structure I - blockmodels\n\n\n13\nModeling network structure II - QAP & ERGMs",
    "crumbs": [
      "Getting started",
      "About this course"
    ]
  },
  {
    "objectID": "00-simple-example.html",
    "href": "00-simple-example.html",
    "title": "A simple network analysis in four lines of code",
    "section": "",
    "text": "The goal of this tutorial is to demonstrate how easy it is to do network analysis in R! It emulates the typical process of most analyses, starting at loading network data from a file and then moving on to computing some property of interest and finally to visualizing the result.\nThe document you’re looking at right now is a quarto markdown document (with the .qmd file extension), which allows us to combine (1) prose to explain and document what we are doing, (2) code to run our analysis, and (3) the output of our code, e.g. tables or visualizations.\nAny text you write in this document will be interpreted as prose, styled with markdown. If you want to include code, pressing the / key on your keyboard will show a popup dialogue which allows you to create a code cell in the programming language of your choice (in our case R):\n\n1 + 1 # the hashtag (#) creates a comment, which is not run by R.\n\n[1] 2\n\n\nIf you want to run the code in the cell, you can press the little green arrow symbol. This will show the output of the code below the cell.",
    "crumbs": [
      "Getting started",
      "A basic example"
    ]
  },
  {
    "objectID": "00-simple-example.html#background",
    "href": "00-simple-example.html#background",
    "title": "A simple network analysis in four lines of code",
    "section": "",
    "text": "The goal of this tutorial is to demonstrate how easy it is to do network analysis in R! It emulates the typical process of most analyses, starting at loading network data from a file and then moving on to computing some property of interest and finally to visualizing the result.\nThe document you’re looking at right now is a quarto markdown document (with the .qmd file extension), which allows us to combine (1) prose to explain and document what we are doing, (2) code to run our analysis, and (3) the output of our code, e.g. tables or visualizations.\nAny text you write in this document will be interpreted as prose, styled with markdown. If you want to include code, pressing the / key on your keyboard will show a popup dialogue which allows you to create a code cell in the programming language of your choice (in our case R):\n\n1 + 1 # the hashtag (#) creates a comment, which is not run by R.\n\n[1] 2\n\n\nIf you want to run the code in the cell, you can press the little green arrow symbol. This will show the output of the code below the cell.",
    "crumbs": [
      "Getting started",
      "A basic example"
    ]
  },
  {
    "objectID": "00-simple-example.html#step-0-loading-packages",
    "href": "00-simple-example.html#step-0-loading-packages",
    "title": "A simple network analysis in four lines of code",
    "section": "Step 0: Loading packages",
    "text": "Step 0: Loading packages\nR’s greatest strength is its ecosystem of packages. Packages (or libraries) extend the functionality provided by base R for a broad range of specific domains, such as network analysis. To load a package (e.g., the readr package to read a variety of file formats), we write library(package) in an R code cell.\n\nlibrary(readr)\n\nLoading a package requires us to have it installed first, which we can do with install.packages(\"readr\"). While we have to load the package each time we open a new R session, we only have to install it once. Because of this, you probably don’t want to include this code in a cell. What you can do instead, is copy-paste the install command into the R console and press enter. In RStudio, the console is by default located in the window below the quarto markdown document.\nFor this tutorial, we will also load the network and sna packages, which contain functionality to perform network analysis in R:\n\nlibrary(network)\n\n\n'network' 1.18.2 (2023-12-04), part of the Statnet Project\n* 'news(package=\"network\")' for changes since last version\n* 'citation(\"network\")' for citation information\n* 'https://statnet.org' for help, support, and other information\n\nlibrary(sna)\n\nLoading required package: statnet.common\n\n\n\nAttaching package: 'statnet.common'\n\n\nThe following objects are masked from 'package:base':\n\n    attr, order\n\n\nsna: Tools for Social Network Analysis\nVersion 2.7-2 created on 2023-12-05.\ncopyright (c) 2005, Carter T. Butts, University of California-Irvine\n For citation information, type citation(\"sna\").\n Type help(package=\"sna\") to get started.\n\n\nIf we haven’t installed the packages yet, we need to do so before we can load them, as described above.",
    "crumbs": [
      "Getting started",
      "A basic example"
    ]
  },
  {
    "objectID": "00-simple-example.html#step-1-loading-data",
    "href": "00-simple-example.html#step-1-loading-data",
    "title": "A simple network analysis in four lines of code",
    "section": "Step 1: Loading data",
    "text": "Step 1: Loading data\nWith the readr package installed and loaded into our R session, we are now ready to load the data containing our network. Here, the network is represented by an edgelist (a specific kind of network data format which we will learn more about in the coming sessions) contained in a .csv file (a comma-separated-values file), which we could also look at in Excel or a text editor.\n\nedgelist &lt;- read_csv(\"data/edgelist.csv\")\n\nRows: 30 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): sender, receiver\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThere are multiple things going on in this one line of code:\n\nWe use the read_csv(…) function to load data from a .csv file\nWe pass the (relative) path to our .csv file as an argument to read_csv, in the \"string\" format\nWe assign the data read by the read_csv function to a variable named edgelist using the assignment operator &lt;-\n\nIf we look at the edgelist variable by clicking on it in the global environment viewer (top right), we see something very similar to an excel spreadsheet. Rectangular data containing many observations for multiple variables, such as typically contained in a spreadsheet, is in R represented by a data.frame.",
    "crumbs": [
      "Getting started",
      "A basic example"
    ]
  },
  {
    "objectID": "00-simple-example.html#step-2-creating-a-network",
    "href": "00-simple-example.html#step-2-creating-a-network",
    "title": "A simple network analysis in four lines of code",
    "section": "Step 2: Creating a network",
    "text": "Step 2: Creating a network\nBy itself, R doesn’t know that it should treat the data in our edgelist data frame as representing a network. Accordingly, we convert our data.frame to a dedicated network object using the network(…) function, where we can also specify some properties of the network, such directedness:\n\nnet &lt;- network(edgelist, directed=FALSE)\n\nIf we just call this network object in a cell, it will show us a helpful summary of our network:\n\nnet\n\n Network attributes:\n  vertices = 10 \n  directed = FALSE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = FALSE \n  total edges= 30 \n    missing edges= 0 \n    non-missing edges= 30 \n\n Vertex attribute names: \n    vertex.names \n\nNo edge attributes\n\n\nThis output tells us, among other things, that our network contains 10 nodes and 30 edges.",
    "crumbs": [
      "Getting started",
      "A basic example"
    ]
  },
  {
    "objectID": "00-simple-example.html#step-3-computing-centrality",
    "href": "00-simple-example.html#step-3-computing-centrality",
    "title": "A simple network analysis in four lines of code",
    "section": "Step 3: Computing centrality",
    "text": "Step 3: Computing centrality\nWe can now use a variety of functions on this network object to compute a broad range of quantities of interest, such as the degree centrality of each node (the node’s number of contacts):\n\ndeg &lt;- degree(net)\ndeg\n\n [1] 12 10 12 10 18 10 14 10 14 10\n\n\nThe result is a vector of values, where e.g. the first value tells us that the first node in the network has a total of 6 contacts.",
    "crumbs": [
      "Getting started",
      "A basic example"
    ]
  },
  {
    "objectID": "00-simple-example.html#step-4-plotting-the-network",
    "href": "00-simple-example.html#step-4-plotting-the-network",
    "title": "A simple network analysis in four lines of code",
    "section": "Step 4: Plotting the network",
    "text": "Step 4: Plotting the network\nFinally, we may want to plot our network, labeling the nodes with their IDs and scaling the node size according to node degree. We can use the gplot(…) function to do so, passing a variety of arguments to control the display of labels, node color, or node size:\n\ngplot(net,\n      gmode=\"graph\",\n      label = 1:10,\n      label.pos = 5,\n      vertex.col=\"grey\",\n      vertex.cex=sqrt(deg))\n\n\n\n\n\n\n\n\nLooking at the plot, we can immediately see that node 5 is the most central, having a total of 9 connections to other nodes.",
    "crumbs": [
      "Getting started",
      "A basic example"
    ]
  },
  {
    "objectID": "00-simple-example.html#putting-it-all-together",
    "href": "00-simple-example.html#putting-it-all-together",
    "title": "A simple network analysis in four lines of code",
    "section": "Putting it all together",
    "text": "Putting it all together\nAs promised, the above corresponds to a rudimentary network analysis in a total of four lines of code:\n\nedgelist &lt;- read_csv(\"data/edgelist.csv\") # read data from file\nnet &lt;- network(edgelist, directed=FALSE) # create network object \ndeg &lt;- degree(net) # compute degree centrality\ngplot(net, gmode=\"graph\",\n      label=1:10, label.pos=5, \n      vertex.col=\"grey\", vertex.cex=sqrt(deg)) # plot the network",
    "crumbs": [
      "Getting started",
      "A basic example"
    ]
  },
  {
    "objectID": "02-loading-data.html",
    "href": "02-loading-data.html",
    "title": "R Basics II",
    "section": "",
    "text": "The first step for any R analysis is getting data into an R session. While it sounds like this should be easy, data loading can be quite a hassle due to an unending variety of data formats, which are often only weakly specified. Due to this, data loading can be quite frustrating, especially when one is just getting started.\nNevertheless, there is a variety of packages which can help us with this step. Let’s try two of the most common formats:\n\n\nSometimes we want to send our data to a colleague, who might only be familiar with excel. So as a first step, we’re going to write the gapminder data to an excel spreadsheet. Let’s have a look at our data first:\n\nlibrary(gapminder)\ngapminder\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\nWe can see that there’s 1704 rows (observations) and 6 columns (variables). Let’s write it to an excel file:\n\nlibrary(openxlsx)\n\nwrite.xlsx(gapminder,\n           file = \"data/gapminder.xlsx\",\n           colNames=TRUE)\n\nIn our working directory, there should now be the gapminder.xlsx file, containing a sheet with our data frame. There’s a variety of formatting options, but usually you should regard excel as a mere transport format and not as the final styled output.\nHaving created an excel file, we can also go the other way. Let’s read our data back into an R data.frame. For reading excel files, I would usually recommend the readxl package, which is part of the extended tidyverse:\n\nlibrary(readxl)\n\ndf &lt;- read_excel(\"data/gapminder.xlsx\")\ndf\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\n\n\n\nOne of the most wide-spread formats is .csv (for comma-separated values). It is a very simple and lightweight but also somewhat restrictive and underspecified format (e.g. regarding delimiter, headers, data types, sentinel values, etc.).\nWhile there’s a built-in function to read from csv, we’re again going to rely on the tidyverse here, which contains the readr package, providing this functionality.\n\nlibrary(readr)\n\nWe’ll follow the same procedure as before, first writing the gapminder data to a csv file and then reading it back again:\n\nwrite_csv(gapminder, file = \"data/gapminder.csv\")\n\nThere should now be a gapminder.csv file in your working directory, which you can also view with RStudio (click it in the file viewer).\nLet’s read it back in again:\n\ndf2 &lt;- read_csv(\"data/gapminder.csv\")\n\nRows: 1704 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): country, continent\ndbl (4): year, lifeExp, pop, gdpPercap\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndf2\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;chr&gt;       &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\nWhen loading a csv file with read_csv, we get some information about the automatic detection of parsing specifications (e.g. the detected delimiter and column types).\n\n\n\n\nIdentify the data format of the file data.csv and find a function/package to load your data into R.\nIdentify the correct specification and arguments for loading your data and load your data into a data.frame.\n\n\n\nSolution\nlibrary(readr)\ndata &lt;- read_csv2(\"data/data.csv\")",
    "crumbs": [
      "`R` programming basics",
      "Loading data"
    ]
  },
  {
    "objectID": "02-loading-data.html#exercises",
    "href": "02-loading-data.html#exercises",
    "title": "R Basics II",
    "section": "",
    "text": "Identify the data format of the file data.csv and find a function/package to load your data into R.\nIdentify the correct specification and arguments for loading your data and load your data into a data.frame.\n\n\n\nSolution\nlibrary(readr)\ndata &lt;- read_csv2(\"data/data.csv\")",
    "crumbs": [
      "`R` programming basics",
      "Loading data"
    ]
  },
  {
    "objectID": "04-plotting.html",
    "href": "04-plotting.html",
    "title": "R basics IV",
    "section": "",
    "text": "Our first plot\nIn the following, we will look at the gapminder dataset, which contains information on life expectancy and GDP per capita for more than 140 countries over a period of more than 50 years. Based on this data, we investigate the relationship between life expectancy and economic development across the world.\n\nlibrary(gapminder)\ngapminder\n\n# A tibble: 1,704 × 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ℹ 1,694 more rows\n\n\nFor plotting, we use the ggplot2 package, which is contained in the tidyverse. The fundamental building block for any plot is a call to the ggplot() function, to which we pass the data that we want to plot. On its own, this just creates a blank plot, as we haven’t specified which variables we want to plot and how we want to plot them:\n\nlibrary(ggplot2)\n\np &lt;- ggplot(data = gapminder)\np\n\n\n\n\n\n\n\n\nTo do so, we have to specify an aesthetic mapping from our data variables to the visual elements of our plot (such as positions or colors). This allows us to specify that we want to display variation in GDP along the x-axis and life expectancy along the y-axis:\n\np &lt;- ggplot(data = gapminder,              \n            mapping = aes(x = gdpPercap, y = lifeExp))\np\n\n\n\n\n\n\n\n\nWe can see that our plot now contains axis labels and ticks informed by the range of the data, but there is still no visual representation of the data, because we haven’t specified what kind of plot we want.\nggplot operates in terms of layers which we can add to our basic plot specification with + to include specific geometric representations of our data (such as points in a scatterplot):\n\np + geom_point()\n\n\n\n\n\n\n\n\nAt this point we have a basic plot, which we can now customize to our heart’s content.\n\n\nExercises (20 mins)\nUse the jointly created code and add to it to solve the following tasks:\n\nChange the color of the points to blue.\n\n\n\nSolution\nggplot(gapminder, aes(x=gdpPercap, y=lifeExp)) +   \n  geom_point(color=\"blue\")\n\n\n\nMake the points transparent, so that it is easier to see overlapping data.\n\n\n\nSolution\nggplot(gapminder, aes(x=gdpPercap, y=lifeExp)) +   \n  geom_point(color=\"blue\", alpha=0.2)\n\n\n\nSpecify a log scale for GDP.\n\n\n\nSolution\nggplot(gapminder, aes(x=gdpPercap, y=lifeExp)) +   \n  geom_point(color=\"blue\", alpha=0.2) +   \n  scale_x_log10()\n\n\n\nColor the points by continent.\n\n\n\nSolution\nggplot(gapminder, aes(x=gdpPercap, y=lifeExp, color=continent)) +   \n  geom_point() + \n  scale_x_log10()\n\n\n\nAdd more readable labels to the plot.\n\n\n\nSolution\nggplot(gapminder, aes(x=gdpPercap, y=lifeExp, color=continent)) +   \n  geom_point() + \n  scale_x_log10() +   \n  labs(x=\"GDP per capita (log scale)\", y=\"Life expectancy (years)\")\n\n\n\nAdd a title and a subtitle to the plot.\n\n\n\nSolution\nggplot(gapminder, aes(x=gdpPercap, y=lifeExp, color=continent)) +   \n  geom_point() +\n  scale_x_log10() +\n  labs(     \n    x=\"GDP per capita (log scale)\",      \n    y=\"Life expectancy (years)\",     \n    title=\"GDP vs. life expectancy\",     \n    subtitle=\"Data for ~130 countries over a period of 60 years\")\n\n\n\nApply a different theme to your plot.\n\n\n\nSolution\nggplot(gapminder, aes(x=gdpPercap, y=lifeExp, color=continent)) +   \n  geom_point() + \n  scale_x_log10() +   \n  theme_minimal() + \n  labs(\n    x=\"GDP per capita (log scale)\",      \n    y=\"Life expectancy (years)\",     \n    title=\"GDP vs. life expectancy\",     \n    subtitle=\"Data for ~130 countries over a period of 60 years\")  \n\n\n\nMove the legend to the bottom of the plot.\n\n\n\nSolution\nggplot(gapminder, aes(x=gdpPercap, y=lifeExp, color=continent)) +   \n  geom_point() + \n  scale_x_log10() +   \n  theme_minimal() + \n  theme(legend.position=\"bottom\") +\n  labs(     \n    x=\"GDP per capita (log scale)\",      \n    y=\"Life expectancy (years)\",     \n    title=\"GDP vs. life expectancy\",     \n    subtitle=\"Data for ~130 countries over a period of 60 years\")  \n\n\n\nAdd a regression line to the plot.\n\n\n\nSolution\nggplot(gapminder, aes(x=gdpPercap, y=lifeExp, color=continent)) +   \n  geom_point() + \n  geom_smooth(method=\"lm\", color=\"red\") +\n  scale_x_log10() +   \n  theme_minimal() + \n  theme(legend.position=\"bottom\") +\n  labs(     \n    x=\"GDP per capita (log scale)\",      \n    y=\"Life expectancy (years)\",     \n    title=\"GDP vs. life expectancy\",     \n    subtitle=\"Data for ~130 countries over a period of 60 years\")  \n\n\n\nSave the plot as a .png file.\n\n\n\nSolution\np1 &lt;- ggplot(gapminder, aes(x=gdpPercap, y=lifeExp, color=continent)) +   \n  geom_point() + \n  geom_smooth(method=\"lm\", color=\"red\") +\n  scale_x_log10() +   \n  theme_minimal() + \n  theme(legend.position=\"bottom\") +\n  labs(     \n    x=\"GDP per capita (log scale)\",      \n    y=\"Life expectancy (years)\",     \n    title=\"GDP vs. life expectancy\",     \n    subtitle=\"Data for ~130 countries over a period of 60 years\")  \n\n\nggsave(\"gdp-lifeexp.png\", p1, width=30, height=20, units = \"cm\")\n\n\n\nVisualize the population development by continent. Think about what you would want the plot to look like first and then identify the corresponding geom_*.\n\n\n\nSolution\ndat &lt;- gapminder |&gt; \n    group_by(year, continent) |&gt;\n    summarize(pop=sum(pop))\n\nggplot(dat, aes(x=year, y=pop, color=continent)) +\n    geom_line() +\n    theme_minimal() +\n    theme(legend.position=\"bottom\") + \n    labs(x=\"\", y=\"Population\", title=\"Population growth by continent\")",
    "crumbs": [
      "`R` programming basics",
      "Data visualization"
    ]
  },
  {
    "objectID": "06-network-types.html",
    "href": "06-network-types.html",
    "title": "Different Types of Networks",
    "section": "",
    "text": "Networks can be categorized in various ways depending on their characteristics. We will cover three types of networks here: directed and undirected networks, weighted and unweighted networks, and unipartite and bipartite networks.\nAs usual, we start by loading the necessary packages into our session:\nlibrary(network)\nlibrary(sna)\nlibrary(readr)",
    "crumbs": [
      "Networks in `R`",
      "Network types"
    ]
  },
  {
    "objectID": "06-network-types.html#directed-and-undirected-networks",
    "href": "06-network-types.html#directed-and-undirected-networks",
    "title": "Different Types of Networks",
    "section": "Directed and undirected networks",
    "text": "Directed and undirected networks\nA directed network (or digraph) is a network where the edges have a direction, i.e., they distinguish between a source and a target node. Inherent asymmetry of ties is the case for many real world networks, such as advice giving, money lending, or the transmission of infectious diseases.\nHowever, not all relations are inherently asymmetric (e.g., friendships), and sometimes it is necessary to drop edge directions for analytic reasons.\nIn R, we can specify upon construction whether a network should be directed or not, using the directed = TRUE/FALSE flag. E.g. for this data frame representing an edgelist:\n\nedgelist &lt;- data.frame(\n  sender   = c(1,1,2,2,3,3,3),\n  receiver = c(2,3,1,4,1,2,4)\n)\n\nWe can construct a directed network in the following way:\n\ndirected &lt;- network(edgelist, directed = TRUE)\n\n\nSymmetrization\nIf we have a directed network but want an undirected one, we can symmetrize it. Networks can be symmetrized in multiple different ways, with the two common rules being the “weak” rule and the “strong” rule.\nWeak rule symmetrization is the more permissive approach and adds an undirected edge between two nodes if there is an edge in at least one direction in the original network. In contrast, the strong rule requires an edge to be present in both directions for the edge to be present in the symmetrized network.\nSymmetrization can be achieved in R using the symmetrize(...) function:\n\nadj_sym &lt;- symmetrize(directed, rule = \"weak\")\n\nSince this function returns a symmetrized adjacency matrix, we also need to reconstruct our network if we want a network object, where we also explicitly pass directed = FALSE:\n\nnet_sym &lt;- network(adj_sym, directed=FALSE)\n\n\n\nPlotting directed and undirected networks\nDirected edges are usually represented by arrows in a network plot. If we pass a directed network to gplot(...), this is the default (because the default value of the gmode argument is digraph):\n\ngplot(directed, label = 1:4)\n\n\n\n\n\n\n\n\nIf we want to plot an undirected network, we include gmode = \"digraph\" in the call to gplot:\n\ngplot(net_sym, gmode = \"graph\", label = 1:4)",
    "crumbs": [
      "Networks in `R`",
      "Network types"
    ]
  },
  {
    "objectID": "06-network-types.html#weighted-and-unweighted-networks",
    "href": "06-network-types.html#weighted-and-unweighted-networks",
    "title": "Different Types of Networks",
    "section": "Weighted and unweighted networks",
    "text": "Weighted and unweighted networks\nA weighted network is a network where the edges have weights representing the strength or intensity of the relationship between nodes.\nSimilarly to directed networks, edge weights are common in many real-world scenarios, such as transportation or trade networks, where weights could represent the distance or trade volume between countries.\nThe easiest way to construct a weighted network in R is by passing an adjacency matrix to the network function where the cells represent edge weights and not just the presence or absence of an edge.\nTo demonstrate, we can simulate a weighted adjacency matrix with random values:\n\nadj_weighted &lt;- matrix(rnorm(16), nrow = 4, ncol = 4)\nadj_weighted\n\n           [,1]        [,2]       [,3]       [,4]\n[1,] -0.6030230 -0.26714468 -0.3651462  0.9598961\n[2,]  1.3653667 -1.74569287  0.4231739  0.5669126\n[3,] -0.9468761 -0.08052606  1.1921851 -1.9213248\n[4,]  0.3121404  0.35747477 -0.1266203  1.9689559\n\n\nBy default, the network(...) function ignores edge values/weights. We here accordingly specify ignore.eval = FALSE and specify a name for our weights by setting names.eval = \"name\":\n\nnet_weighted &lt;- network(adj_weighted, \n                        ignore.eval = FALSE, \n                        names.eval = \"weight\")\nnet_weighted\n\n Network attributes:\n  vertices = 4 \n  directed = TRUE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = FALSE \n  total edges= 12 \n    missing edges= 0 \n    non-missing edges= 12 \n\n Vertex attribute names: \n    vertex.names \n\n Edge attribute names: \n    weight \n\n\n\nDichotomization\nIf we have a weighted network but want a simple unweighted network, where edges are either present or not, we can dichotomize the adjacency matrix. This just means picking a threshold value and keeping all edges above that value while discarding the rest.\nWe can accomplish this in R using the ifelse(...) function, which checks a condition and returns one or another value depending on whether it is met:\n\nthresh &lt;- 0.3 # threshold value\nadj_dicho &lt;- ifelse(adj_weighted &gt; thresh, 1, 0)\nadj_dicho\n\n     [,1] [,2] [,3] [,4]\n[1,]    0    0    0    1\n[2,]    1    0    1    1\n[3,]    0    0    1    0\n[4,]    1    1    0    1\n\n\nIn the dichotomized matrix, all cells with a value of \\(0.3\\) or more are set to \\(1\\) while all cells below the threshold are set to a \\(0\\). We can then pass the dichotomized adjacency matrix to the network constructor again:\n\nnet_dicho &lt;- network(adj_dicho)\n\n\n\nPlotting weighted networks\nIf we want to include weights in our plot, we can scale the width of the edges in the plot according to their weight by setting the argument edge.lwd to the weighted adjacency matrix (possibly multiplied by a scaling factor or transformed by some other function):\n\ngplot(net_weighted, edge.lwd = 8 * adj_weighted)",
    "crumbs": [
      "Networks in `R`",
      "Network types"
    ]
  },
  {
    "objectID": "06-network-types.html#unipartite-vs.-bipartite-networks",
    "href": "06-network-types.html#unipartite-vs.-bipartite-networks",
    "title": "Different Types of Networks",
    "section": "Unipartite vs. bipartite networks",
    "text": "Unipartite vs. bipartite networks\nAnother commonly encountered type of network are bipartite (or bimodal) networks. In a bipartite network, there are two different kinds of nodes and only nodes of different kinds can be connected through an edge.\nA classical example of this is a network of event attendances where the two different sets of nodes represent people and events, respectively, and edges indicate that a person attended an event.\nBipartite networks are easily represented with a regular edgelist:\n\nedgelist &lt;- data.frame(\n  person = c(\"A\", \"A\", \"A\", \"B\", \"B\"),\n  event  = c(\"X\", \"Y\", \"Z\", \"X\", \"Y\")\n)\n\nTo construct a network object, we can pass this to the network constructor alongside the bipartite = TRUE flag:\n\nnet_bipartite &lt;- network(edgelist, bipartite = TRUE, directed = FALSE)\nnet_bipartite\n\n Network attributes:\n  vertices = 5 \n  directed = FALSE \n  hyper = FALSE \n  loops = FALSE \n  multiple = FALSE \n  bipartite = 2 \n  total edges= 5 \n    missing edges= 0 \n    non-missing edges= 5 \n\n Vertex attribute names: \n    vertex.names \n\nNo edge attributes\n\n\nThe bipartite = 2 in the printed summary indicates the number of nodes in the first partition.\n\nProjecting bipartite networks\nThere are two unipartite networks we could create from our bipartite network by projection:\n\nA network of events which indicates whether two events were visited by the same people.\nA network of people which indicates whether two people attended the same events.\n\nWe can obtain both of these with a little bit of linear algebra on the incidence matrix, which, as opposed to a regular adjacency matrix, is not necessarily quadratic anymore:\n\ninc &lt;- as.matrix(net_bipartite)\ninc\n\n  X Y Z\nA 1 1 1\nB 1 1 0\n\n\nIf we multiply this matrix with its transpose, we obtain a weighted adjacency matrix representing the co-attendance count for the two people in the network:\n\ninc %*% t(inc)\n\n  A B\nA 3 2\nB 2 2\n\n\nIf we change the order of the factors in the product, we obtain the co-attendance matrix for events:\n\nt(inc) %*% inc\n\n  X Y Z\nX 2 2 1\nY 2 2 1\nZ 1 1 1\n\n\nWe can then proceed to create networks from these, as for regular weighted adjacency matrices.\n\n\nPlotting bipartite networks\nWe can use the bipartite nature of this network for plotting by passing the gmode = \"twomode\" flag to the gplot(...) function. This will show the two sets of nodes in different colors and with different symbols:\n\ngplot(net_bipartite, gmode = \"twomode\", usearrows = FALSE)",
    "crumbs": [
      "Networks in `R`",
      "Network types"
    ]
  },
  {
    "objectID": "06-network-types.html#exercises",
    "href": "06-network-types.html#exercises",
    "title": "Different Types of Networks",
    "section": "Exercises",
    "text": "Exercises\n\nLoad the advice network in the file data/lazega_advice.csv into a directed network object.\n\n# Write your code here...\n\nSymmetrize the network using the weak rule.\n\n# Write your code here...\n\nSymmetrize the network using the strong rule.\n\n# Write your code here...\n\nPlot the symmetrized network next to the original with the correct arguments for an undirected network.\n\npar(mfrow=c(1,2)) # DON'T CHANGE THIS\n\n# Write your plotting functions here...\n\nCompare the two symmetrized variants visually and in terms of their basic properties. What do you observe?\n\n# Write your code here...",
    "crumbs": [
      "Networks in `R`",
      "Network types"
    ]
  },
  {
    "objectID": "08-structural-holes.html",
    "href": "08-structural-holes.html",
    "title": "Structural Holes and Ego-networks",
    "section": "",
    "text": "In the operationalization of his structural hole theory, Ron Burt (1992) devised a set of measures that quantify the degree to which an actor can access distinct resources through their contacts. In the following, we will explore these measures in the context of the Florentine families’ marriage network, which we is contained in the statnet suite:\nlibrary(statnet)\ndata(florentine)\nThe structural hole measures are not included in either statnet or igraph, but they are not that hard to implement, so we will implement our own as we go.",
    "crumbs": [
      "Node-level indicators",
      "Structural holes"
    ]
  },
  {
    "objectID": "08-structural-holes.html#exercises",
    "href": "08-structural-holes.html#exercises",
    "title": "Structural Holes and Ego-networks",
    "section": "Exercises",
    "text": "Exercises\n\nLoad the Lazega advice network into an R session.\n\n\n\nSolution\nadjmat &lt;- read.table(\"data/lazega_advice.csv\", \n                     sep =\";\", \n                     header = TRUE, \n                     row.names = 1, \n                     check.names = FALSE)\n\nadjmat &lt;- as.matrix(adjmat)\n\nnet_advice &lt;- network(adjmat)\n\n\n\nSymmetrize the network, using the weak rule.\n\n\n\nSolution\nnet_sym &lt;- network(symmetrize(net_advice), directed=FALSE)\n\n\n\nExtract the ego-networks for node 40 and node 33.\n\n\n\nSolution\ne1 &lt;- network(ego.extract(net_sym, ego=33)[[\"33\"]], directed=FALSE)\ne2 &lt;- network(ego.extract(net_sym, ego=40)[[\"40\"]], directed=FALSE)\n\n\n\nPlot the two ego-networks side by side. Color the ego node differently than the alteri and increase its size.\n\n\n\nSolution\npar(mfrow = c(1,2), mar=c(0,0,3,0))\n\ngplot(e1,\n      gmode = \"graph\",\n      vertex.col = c(\"red\", rep(\"grey20\", network.size(e1) - 1)),\n      vertex.cex = c(2, rep(1, network.size(e1) - 1)),\n      edge.col = \"grey70\")\n\ngplot(e2,\n      gmode = \"graph\",\n      vertex.col = c(\"red\", rep(\"grey20\", network.size(e2) - 1)),\n      vertex.cex = c(2, rep(1, network.size(e2) - 1)),\n      edge.col = \"grey70\")\n\n\n\n\n\n\n\n\n\n\nCompute the degree centrality, effective size, and efficiency for the two nodes. What do you observe?\n\n\n\nSolution\ndegree(e1)[1]\n\n\n[1] 44\n\n\nSolution\ndegree(e2)[1]\n\n\n[1] 52\n\n\nSolution\negonet_effsize(e1)\n\n\n[1] 13.63636\n\n\nSolution\negonet_effsize(e2)\n\n\n[1] 11.61538\n\n\nSolution\negonet_efficiency(e1)\n\n\n[1] 0.6198347\n\n\nSolution\negonet_efficiency(e2)\n\n\n[1] 0.4467456\n\n\n\nCompute the degree, constraint, effective size, and efficiency for all nodes in the network.\n\n\n\nSolution\ndegree &lt;- degree(net_sym)\nconstraint &lt;- apply_egonet(net_sym, egonet_constraint)\neffsize &lt;- apply_egonet(net_sym, egonet_effsize)\nefficiency &lt;- apply_egonet(net_sym, egonet_efficiency)\n\n\n\nCreate a pairs plot (see session on centrality) of the structural hole measures and degree centrality. What do you observe?\n\n\nsource(\"helpers/pairsplot.R\") # load helper script to improve the plot\n\nmeasures &lt;- cbind(degree, constraint, effsize, efficiency)\n\npairs(measures,\n      upper.panel = panel.cor,\n      diag.panel = panel.hist)",
    "crumbs": [
      "Node-level indicators",
      "Structural holes"
    ]
  }
]